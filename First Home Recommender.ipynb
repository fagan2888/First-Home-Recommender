{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Home Recommender\n",
    "## AHS Household Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook imports the combined household dataset from the American Housing Survey and readys it for machine learning with various transformations.\n",
    "\n",
    "Steps:\n",
    "01 - Subset the household dataset for first-time homeowners only.\n",
    "02 - Remove weight and flag variales from the household dataset.\n",
    "03 - Remove all variables related to house \"experience\"\n",
    "04 - Remove variables whose portion of missing values is above the threshhold level.\n",
    "05 - Impute the missing values for continuous, categorical, and binary variables.\n",
    "06 - Create a dummy variable dataset from categorical variables.\n",
    "07 - Bin the housing satisfaction target variale.\n",
    "08 - Scale dollar value variales from 0 to 1.0.\n",
    "09 - Log transform income variables.\n",
    "10 - Combine datasets together into regression and classification model-ready datasets.\n",
    "11 - Update the AWS database.\n",
    "\n",
    "NOTE: Each of these steps needs to be run numerical order for final datasets to be created correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate Relevant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshhold = 0.20\n",
    "path = os.path.join(os.getcwd(), 'data', 'working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(path, 'AHS Household Combined.csv'))\n",
    "varcat = pd.read_csv(os.path.join(os.getcwd(), 'data', 'concordance', 'varclass.csv'))\n",
    "varrelevant = pd.read_csv(os.path.join(os.getcwd(), 'data', 'concordance', 'varrelevant.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01 - Subset the dataset to only first-time home buyers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fh = df[df['FIRSTHOME']==1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02 - Remove weight and flag variales from the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_less_wgt = [i for i in list(df_fh.columns) if 'WGT' not in i]\n",
    "vars_less_wgt = [i for i in vars_less_wgt if 'WEIGHT' not in i]\n",
    "vars_less_wgt_flags = [i for i in vars_less_wgt if not i.startswith('J')]\n",
    "df_fh2 = df_fh[vars_less_wgt_flags].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03 - Remove all variables related to house experience\n",
    "\n",
    "The project's goal is to predict housing satisfaction using features relevant to a housing search. Therefore, any field that captures information on actual housing experience after the point of purchase should not be included in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_vars = list(varrelevant[varrelevant.iloc[:,1]].iloc[:,0])\n",
    "df_fh3 = df_fh2[['CONTROL','YEAR'] + relevant_vars].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04 - Remove variables whose portion of missing values is above the threshhold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_percent = df_fh3.isin([-9]).sum(axis=0) / df_fh3.count(axis=0)\n",
    "miss_percent_lt_thresh = miss_percent[miss_percent.iloc[:] < threshhold]\n",
    "df_fh4 = df_fh3[miss_percent_lt_thresh.index].copy()\n",
    "df_fh4_cols = list(df_fh2.columns)\n",
    "df_fh4.replace(-9, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "05 - Impute missing values for all estimators\n",
    "\n",
    "Divide the list of remaining variales into 4 groups: 1) target, 2) continuous, 3) categorical, and 4) binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_varcat = pd.merge(pd.DataFrame(miss_percent_lt_thresh), varcat, how='left', \n",
    "                     left_on=pd.DataFrame(miss_percent_lt_thresh).index, right_on=['Variable'])\n",
    "target_vars = list(df_varcat['Variable'][df_varcat['Grouping'] == 'Target'])\n",
    "cont_vars = list(df_varcat['Variable'][df_varcat['Grouping'] == 'Continuous'])\n",
    "cat_vars = list(df_varcat['Variable'][df_varcat['Grouping'] == 'Categorical'])\n",
    "binary_vars = list(df_varcat['Variable'][df_varcat['Grouping'] == 'Binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_vars = ['ELECAMT','GASAMT','OILAMT','OTHERAMT','TRASHAMT','WATERAMT','UTILAMT']\n",
    "scale_vars = ['EXPSUM','HINCP','FINCP']\n",
    "inc_vars = ['HINCP','FINCP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate dataset into target variables and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_fh4[['CONTROL','YEAR','RATINGHS']].copy()\n",
    "estimators = df_fh4.drop(['RATINGHS','RATINGNH'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing data values for each type of variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_cont = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputer_cont.fit(estimators[['CONTROL','YEAR'] + cont_vars])\n",
    "imputed_cont = imputer_cont.transform(estimators[['CONTROL','YEAR'] + cont_vars])\n",
    "estimators_cont = pd.DataFrame(imputed_cont, columns=['CONTROL','YEAR'] + cont_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_cat = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputer_cat.fit(estimators[['CONTROL','YEAR'] + cat_vars])\n",
    "imputed_cat = imputer_cat.transform(estimators[['CONTROL','YEAR'] + cat_vars])\n",
    "estimators_cat = pd.DataFrame(imputed_cat, columns=['CONTROL','YEAR'] + cat_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_binary = estimators[['CONTROL','YEAR'] + binary_vars].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06 - Create dummies from categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_cat_dum = pd.get_dummies(estimators_cat, columns=cat_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "07 - Bin Housing Satisfaction Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "target['RATINGHS_BIN'] = pd.cut(target['RATINGHS'], bins=[0,7,8,9,10], \n",
    "                                labels=['not satisfied','satisfied','very satisfied','extremely satisfied'])\n",
    "target_bin = pd.DataFrame(target[['CONTROL','YEAR','RATINGHS_BIN']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "08 - Scale the dollar value variales from 0 to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_cont['EXPSUM'] = estimators_cont[exp_vars].sum(axis=1)\n",
    "estimators_cont.drop(exp_vars, axis=1)\n",
    "\n",
    "x_array = estimators_cont[scale_vars]\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x_array)\n",
    "scaled_cont = pd.DataFrame(x_scaled, columns=scale_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "09 - Log transform both income variales and merge back into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_cont[['LN_HINCP','LN_FINCP']] = scaled_cont[inc_vars].apply(np.log, inplace=True)\n",
    "scaled_cont.drop(inc_vars, axis=1, inplace=True)\n",
    "estimators_cont_inc = pd.concat([estimators_cont[['CONTROL','YEAR']],pd.DataFrame(scaled_cont)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_cont_noninc = estimators_cont.drop(['ELECAMT','GASAMT','OILAMT','OTHERAMT','TRASHAMT','WATERAMT',\n",
    "                                               'UTILAMT','EXPSUM','HINCP','FINCP'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 - Merge datasets with different variable types back into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_reg = [target, estimators_cont_inc, estimators_cont_noninc, estimators_cat_dum, estimators_binary]\n",
    "dfs_class = [target_bin, estimators_cont_inc, estimators_cont_noninc, estimators_cat, estimators_binary]\n",
    "df_final_reg = reduce(lambda left, right: pd.merge(left, right, how='inner', on=['CONTROL','YEAR']), dfs_reg).dropna(how='any')\n",
    "df_final_class = reduce(lambda left, right: pd.merge(left, right, how='inner', on=['CONTROL','YEAR']), dfs_class).dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_reg.to_csv(os.path.join(path, 'AHS Household Reg.csv'))\n",
    "df_final_class.to_csv(os.path.join(path, 'AHS Household Class.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 - Update Database\n",
    "\n",
    "Send intermediate tables to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://postgres:Admin123@project.cgxhdwn5zb5t.us-east-1.rds.amazonaws.com:5432/postgres')\n",
    "df_fh4.to_sql('ahs_household_step_4', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "df_tables = {'ahs_household_step_1':df_fh, \n",
    "             'ahs_household_step_4':df_fh4, \n",
    "             'ahs_household_class':df_final_class,\n",
    "             'ahs_household_reg':df_final_reg}\n",
    "engine = create_engine('postgresql://postgres:Admin123@project.cgxhdwn5zb5t.us-east-1.rds.amazonaws.com:5432/postgres')\n",
    "\n",
    "for name, df in df_tables.items():\n",
    "    df.to_sql('{}'.format(name), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
