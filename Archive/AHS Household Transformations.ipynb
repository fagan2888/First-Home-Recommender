{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Home Recommender\n",
    "## AHS Household Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook imports the combined household dataset from the American Housing Survey and readys it for machine learning with various transformations.\n",
    "\n",
    "Steps:\n",
    "01. Subset the household dataset for first-time homeowners only.\n",
    "02. Remove weight and flag variales from the household dataset.\n",
    "03. Remove variables whose portion of missing values is above the threshhold level.\n",
    "04. Impute the missing values for continuous, categorical, and binary variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate Relevant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshhold = 0.20\n",
    "path = os.path.join(os.getcwd(), 'data', 'working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(path, 'AHS Household Combined.csv'))\n",
    "varcat = pd.read_csv(os.path.join(os.getcwd(), 'data', 'concordance', 'varclass.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01 - Subset the dataset to only first-time home buyers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fh = df[df['FIRSTHOME']==1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02 - Remove weight and flag variales from the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_less_wgt = [i for i in list(df_fh.columns) if 'WGT' not in i]\n",
    "vars_less_wgt = [i for i in vars_less_wgt if 'WEIGHT' not in i]\n",
    "vars_less_wgt_flags = [i for i in vars_less_wgt if not i.startswith('J')]\n",
    "df_fh2 = df_fh[vars_less_wgt_flags].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03 - Remove variables whose portion of missing values is above the threshhold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_percent = df_fh2.isin([-6, -9]).sum(axis=0) / df_fh2.count(axis=0)\n",
    "miss_percent_lt_thresh = miss_percent[miss_percent.iloc[:] < threshhold]\n",
    "df_fh2 = df_fh[miss_percent_lt_thresh.index].copy()\n",
    "df_fh2_cols = list(df_fh2.columns)\n",
    "df_fh2.replace([-6, -9], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04 - Impute missing values os all estimators\n",
    "\n",
    "Divide the list of remaining variales into 4 groups: 1) target, 2) continuous, 3) categorical, and 4) binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_varcat = pd.merge(pd.DataFrame(miss_percent_lt_thresh), varcat, how='left', \n",
    "                     left_on=pd.DataFrame(miss_percent_lt_thresh).index, right_on=['Variable'])\n",
    "target_vars = list(df_varcat['Variable'][df_varcat['Grouping'] == 'Target'])\n",
    "cont_vars = list(df_varcat['Variable'][df_varcat['Grouping'] == 'Continuous'])\n",
    "cat_vars = list(df_varcat['Variable'][df_varcat['Grouping'] == 'Categorical'])\n",
    "binary_vars = list(df_varcat['Variable'][df_varcat['Grouping'] == 'Binary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate dataset into target variables and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_fh2[['CONTROL','YEAR'] + target_vars].copy()\n",
    "estimators = df_fh2.drop(['RATINGHS','RATINGNH'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing data values for each type of variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_cont = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputer_cont.fit(estimators[['CONTROL','YEAR'] + cont_vars])\n",
    "imputed_cont = imputer_cont.transform(estimators[['CONTROL','YEAR'] + cont_vars])\n",
    "estimators_cont = pd.DataFrame(imputed_cont, columns=['CONTROL','YEAR'] + cont_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_cat = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputer_cat.fit(estimators[['CONTROL','YEAR'] + cat_vars])\n",
    "imputed_cat = imputer_cat.transform(estimators[['CONTROL','YEAR'] + cat_vars])\n",
    "estimators_cat = pd.DataFrame(imputed_cat, columns=['CONTROL','YEAR'] + cat_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_binary = estimators[['CONTROL','YEAR'] + binary_vars].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dummies from categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_cat_dum = pd.get_dummies(estimators_cat, columns=cat_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge different variables back into a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [target, estimators_cont, estimators_cat_dum, estimators_binary]\n",
    "df_final = reduce(lambda left, right: pd.merge(left, right, how='inner', on=['CONTROL','YEAR']), dfs).dropna(how='any')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
