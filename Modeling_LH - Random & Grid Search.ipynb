{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisahuynh/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "import matplotlib\n",
    "import warnings\n",
    "import yellowbrick as yb\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect( \n",
    "                        host = 'project.cgxhdwn5zb5t.us-east-1.rds.amazonaws.com',\n",
    "                        port = 5432, \n",
    "                        user = 'postgres',\n",
    "                        password = 'Admin123',\n",
    "                        database = 'postgres')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEC2FLOAT = psycopg2.extensions.new_type(\n",
    "    psycopg2.extensions.DECIMAL.values,\n",
    "    'DEC2FLOAT',\n",
    "    lambda value, curs: float(value) if value is not None else None)\n",
    "psycopg2.extensions.register_type(DEC2FLOAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('Select * from \"ahshouseholdclass2\"')\n",
    "rows = cursor.fetchall()\n",
    "col_names = []\n",
    "for elt in cursor.description:\n",
    "    col_names.append(elt[0])\n",
    "\n",
    "df = pd.DataFrame(data=rows, columns=col_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'CONTROL', 'YEAR', 'RATINGHS_BIN', 'BEDROOMS', 'STORIES',\n",
       "       'PERPOVLVL', 'HHADLTKIDS', 'HINCP', 'UNITSIZE', 'NUMVETS', 'LOTSIZE',\n",
       "       'UFINROOMS', 'HHAGE', 'PARTNER', 'OTHERAMT', 'KITCHENS', 'NUMSECFAM',\n",
       "       'OILAMT', 'DINING', 'FINCP', 'NUMELDERS', 'WATERAMT', 'GASAMT',\n",
       "       'TOTROOMS', 'HHYNGKIDS', 'NUMSUBFAM', 'BATHROOMS', 'NUMYNGKIDS',\n",
       "       'TRASHAMT', 'NUMOLDKIDS', 'NUMNONREL', 'NUMPEOPLE', 'HHMOVE', 'UTILAMT',\n",
       "       'ELECAMT', 'NUMADULTS', 'MULTIGEN', 'LAUNDY', 'HHOLDKIDS', 'FINROOMS',\n",
       "       'LN_HINCP', 'LN_FINCP', 'HINCP_BIN', 'FINCP_BIN', 'NUMCARE', 'NUMWALK',\n",
       "       'HHRACE', 'OMB13CBSA', 'HSHLDTYPE', 'MVG3COST', 'MVG2COST', 'MILHH',\n",
       "       'HHMAR', 'HHNATVTY', 'COOKFUEL', 'NUMMEMRY', 'NUMERRND', 'NUMSEE',\n",
       "       'BLD', 'NUMHEAR', 'MVG1COST', 'DIVISION', 'FIREPLACE', 'CONDO',\n",
       "       'OWNLOT', 'FRIDGE', 'FIRSTHOME', 'HHCARE', 'NOSTEP', 'WASHER', 'HHSEE',\n",
       "       'KITCHSINK', 'HHERRND', 'WINBARS', 'HHWALK', 'HHHEAR', 'HHSEX',\n",
       "       'HHMEMRY', 'GARAGE', 'DISHWASH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000.0, 50000.0]     2465\n",
       "(30000.0, 40000.0]     2409\n",
       "(20000.0, 30000.0]     2403\n",
       "(50000.0, 60000.0]     2220\n",
       "(60000.0, 70000.0]     2011\n",
       "(10000.0, 20000.0]     2003\n",
       "(70000.0, 80000.0]     1956\n",
       "(80000.0, 90000.0]     1737\n",
       "(90000.0, 100000.0]    1558\n",
       "(0.0, 10000.0]         1346\n",
       "Name: HINCP_BIN, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HINCP_BIN'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extremely satisfied    7021\n",
       "satisfied              5284\n",
       "not satisfied          4887\n",
       "very satisfied         2916\n",
       "Name: RATINGHS_BIN, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RATINGHS_BIN'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>CONTROL</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>RATINGHS_BIN</th>\n",
       "      <th>BEDROOMS</th>\n",
       "      <th>STORIES</th>\n",
       "      <th>PERPOVLVL</th>\n",
       "      <th>HHADLTKIDS</th>\n",
       "      <th>HINCP</th>\n",
       "      <th>UNITSIZE</th>\n",
       "      <th>...</th>\n",
       "      <th>HHSEE</th>\n",
       "      <th>KITCHSINK</th>\n",
       "      <th>HHERRND</th>\n",
       "      <th>WINBARS</th>\n",
       "      <th>HHWALK</th>\n",
       "      <th>HHHEAR</th>\n",
       "      <th>HHSEX</th>\n",
       "      <th>HHMEMRY</th>\n",
       "      <th>GARAGE</th>\n",
       "      <th>DISHWASH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11000006</td>\n",
       "      <td>2017</td>\n",
       "      <td>extremely satisfied</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11000023</td>\n",
       "      <td>2017</td>\n",
       "      <td>satisfied</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11000046</td>\n",
       "      <td>2017</td>\n",
       "      <td>extremely satisfied</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11000048</td>\n",
       "      <td>2017</td>\n",
       "      <td>very satisfied</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11000052</td>\n",
       "      <td>2017</td>\n",
       "      <td>not satisfied</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13200.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11000054</td>\n",
       "      <td>2017</td>\n",
       "      <td>satisfied</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71004.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>11000062</td>\n",
       "      <td>2017</td>\n",
       "      <td>not satisfied</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>11000066</td>\n",
       "      <td>2017</td>\n",
       "      <td>not satisfied</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>11000067</td>\n",
       "      <td>2017</td>\n",
       "      <td>satisfied</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>11000079</td>\n",
       "      <td>2017</td>\n",
       "      <td>satisfied</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   CONTROL  YEAR         RATINGHS_BIN  BEDROOMS  STORIES  PERPOVLVL  \\\n",
       "0      0  11000006  2017  extremely satisfied       3.0      1.0      361.0   \n",
       "1      1  11000023  2017            satisfied       3.0      3.0      501.0   \n",
       "2      2  11000046  2017  extremely satisfied       3.0      1.0       52.0   \n",
       "3      3  11000048  2017       very satisfied       4.0      3.0      406.0   \n",
       "4      4  11000052  2017        not satisfied       4.0      2.0      113.0   \n",
       "5      5  11000054  2017            satisfied       2.0      7.0      501.0   \n",
       "6      6  11000062  2017        not satisfied       2.0      1.0      104.0   \n",
       "7      7  11000066  2017        not satisfied       2.0      1.0      117.0   \n",
       "8      8  11000067  2017            satisfied       2.0      1.0      198.0   \n",
       "9      9  11000079  2017            satisfied       2.0      2.0      302.0   \n",
       "\n",
       "   HHADLTKIDS     HINCP  UNITSIZE  ...  HHSEE  KITCHSINK  HHERRND  WINBARS  \\\n",
       "0         0.0   58700.0       4.0  ...    2.0        1.0      2.0      2.0   \n",
       "1         0.0  100000.0       4.0  ...    2.0        1.0      2.0      2.0   \n",
       "2         0.0   15000.0       2.0  ...    2.0        1.0      2.0      2.0   \n",
       "3         0.0  100000.0       6.0  ...    2.0        1.0      2.0      2.0   \n",
       "4         0.0   13200.0       3.0  ...    2.0        1.0      2.0      2.0   \n",
       "5         0.0   71004.0       3.0  ...    2.0        1.0      2.0      2.0   \n",
       "6         0.0   30200.0       4.0  ...    2.0        1.0      2.0      2.0   \n",
       "7         1.0   29000.0       3.0  ...    2.0        1.0      2.0      2.0   \n",
       "8         0.0   25000.0       3.0  ...    2.0        1.0      1.0      2.0   \n",
       "9         0.0   59000.0       5.0  ...    2.0        1.0      2.0      2.0   \n",
       "\n",
       "   HHWALK  HHHEAR  HHSEX  HHMEMRY  GARAGE  DISHWASH  \n",
       "0     2.0     2.0    2.0      2.0     1.0       1.0  \n",
       "1     2.0     2.0    1.0      2.0     1.0       1.0  \n",
       "2     2.0     2.0    1.0      2.0     1.0       2.0  \n",
       "3     2.0     2.0    2.0      2.0     1.0       1.0  \n",
       "4     2.0     2.0    1.0      2.0     2.0       1.0  \n",
       "5     2.0     2.0    1.0      2.0     2.0       1.0  \n",
       "6     2.0     2.0    1.0      2.0     2.0       1.0  \n",
       "7     2.0     2.0    2.0      2.0     2.0       1.0  \n",
       "8     2.0     2.0    2.0      2.0     2.0       1.0  \n",
       "9     2.0     2.0    1.0      2.0     1.0       1.0  \n",
       "\n",
       "[10 rows x 81 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP = {\n",
    "\"(90000.0, 100000.0]\": 10,\n",
    "\"(80000.0, 90000.0]\": 9,\n",
    "\"(70000.0, 80000.0]\": 8,   \n",
    "\"(60000.0, 70000.0]\": 7,\n",
    "\"(50000.0, 60000.0]\": 6,\n",
    "\"(40000.0, 50000.0]\": 5,\n",
    "\"(30000.0, 40000.0]\": 4,\n",
    "\"(20000.0, 30000.0]\": 3,\n",
    "\"(10000.0, 20000.0]\": 2,\n",
    "\"(0.0, 10000.0]\": 1}\n",
    "\n",
    "# Convert categorical labels into incremental value\n",
    "df['HINCP_BIN'] = df['HINCP_BIN'].map(LABEL_MAP).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP_Y = {\n",
    "\"extremely satisfied\": 3,\n",
    "\"very satisfied\": 2,\n",
    "\"satisfied\": 1,\n",
    "\"not satisfied\": 0\n",
    "}\n",
    "# Convert categorical labels into incremental value\n",
    "df['RATINGHS_BIN'] = df['RATINGHS_BIN'].map(LABEL_MAP_Y).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RATINGHS_BIN'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[['PERPOVLVL', 'NUMELDERS','BEDROOMS','OMB13CBSA','ELECAMT','BATHROOMS', 'HHMOVE',\n",
    "        'UTILAMT', 'DIVISION','UNITSIZE', 'HHNATVTY', 'HINCP_BIN','HHWALK', 'HHHEAR', 'HHSEX',\n",
    "        'GARAGE', 'DISHWASH','DINING', 'LAUNDY']]\n",
    "\n",
    "y = df['RATINGHS_BIN']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm, y_sm = sm.fit_sample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x121b29048>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD0CAYAAACVbe2MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEKtJREFUeJzt3H+s3Xddx/Hnvbv0FLAdKMOMhAFj7p3oiYPdmRZoaTFdypizgMYsBHUQJMQmMrIENuiykqiJCk0gbBl2QtFgohRn7ExZI5B6V/bLWnQnznftGJlGjK6hawE5tb3XP8635OT0/Nr43nN2P30+/vqez/d9vvfzfd/0dT793u/3zCwtLSFJKtfstCcgSVpeBr0kFc6gl6TCGfSSVDiDXpIKNzftCXQ7fPhwA/gF4DvA2SlPR5JWiouAS4FH5+fn2707n1dBTyfkF6Y9CUlaoTYCD/QOPt+C/jsAV155JatWrZr2XIZqtVo0m81pT6MY9rNe9rM+K6GXp0+f5ujRo1BlaK/nW9CfBVi1ahWNRmPacxlpJcxxJbGf9bKf9VlBvex7yds/xkpS4Qx6SSqcQS9JhTPoJalwBr0kFW7kXTcRcRNwU/VyNfA6YDPwKeAMcCAzPx4Rs8BdwFVAG3hfZh6LiPW9tTWfgyRpiJEr+szck5mbM3MzcBj4HeBu4F3ABmBdRLweeDuwOjPfANwKfLI6RL/aFW8F3W61ItjPetnP+pTQy7Hvo4+Ia4CfA24DPpSZT1Tj9wNb6Dx++xWAzHwoIq6JiLVAo0/tkVrPYoTr/vjvePL49+o/8L5jtR3qNT/1E+x//5bajrec7Ge97Gd97GV/z+aBqY8CHwfWAie7xk8Bl1fjz3SNnx1SO1Sr1XoW0xqu0Wjw5PHv8W9Pn6rtmMul1WrRbp/3NRXPK/azXvazPvZysLGCPiJeAkRmfr1apa/p2r0GOAG8qGd8lk7I96sdqtls1vvfpRo/jZfT8/0x6x+xn/Wyn/W5QHvZbreHLpDHvevmzcBXATLzJHA6Il4bETPAVjpfRHYIeBtA9QfYx4bUSpImZNxLNwF8q+v1B4Av0vlqzAOZ+XBEPApcGxHfAGaA9wyqrWXmkqSxjBX0mflHPa8fAtb3jC3SCfXe955XK0maHB+YkqTCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSrc3DhFEXEb8MvAKuAu4CCwB1gCWsD2zFyMiDuA64EzwM2Z+UhEXNGvtubzkCQNMHJFHxGbgTcCbwI2Aa8EdgE7MnMjMANsi4irq/3rgBuBO6tDnFdb8zlIkoYY59LNVuAx4F5gH3AfME9nVQ+wH9gCbAAOZOZSZj4FzEXEJQNqJUkTMs6lm5cBrwJ+CXgN8DfAbGYuVftPARcDa4HjXe87Nz7Tp3aoVqs11uTH0Wg0ajvWcmu1WrTb7WlPYyj7WS/7WR97Odg4QX8c+NfMPA1kRPyQzuWbc9YAJ4CT1Xbv+GKfsaGazWa9v7R9x+o71jJqNpvTnsJ47Ge97Gd9LtBettvtoQvkcS7dPAC8NSJmIuIVwIuBr1bX7gGuAxaAQ8DWiJiNiMvorPqfBo70qZUkTcjIFX1m3hcRbwYeofPBsB14EtgdEauAx4G9mXk2IhaAB7vqAG7pra3/NCRJg4x1e2VmfrjP8KY+dTuBnT1jR/vVSpImwwemJKlwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4ebGKYqIfwROVi+fBD4LfAo4AxzIzI9HxCxwF3AV0Abel5nHImJ9b23N5yBJGmJk0EfEamAmMzd3jX0T+BXgW8DfRsTrgdcAqzPzDVW4fxLYBtzdW5uZR2o/E0lSX+Os6K8CXhQRB6r6nUAjM58AiIj7gS3ApcBXADLzoYi4JiLWDqg16CVpQsYJ+h8AnwDuAX4G2A+c6Np/CrgcWAs80zV+tho72ad2qFarNca0xtNoNGo71nJrtVq02+1pT2Mo+1kv+1kfeznYOEF/FDiWmUvA0Yh4BvjJrv1r6AT/i6rtc2bphPyaPrVDNZvNen9p+47Vd6xl1Gw2pz2F8djPetnP+lygvWy320MXyOPcdfNeOtfbiYhX0An070fEayNiBtgKLACHgLdVdeuBxzLzJHC6T60kaULGWdH/CbAnIh4AlugE/yLwReAiOnfSPBwRjwLXRsQ3gBngPdX7P9BbW/M5SJKGGBn0mXkaeFefXet76hbphHrv+x/qrZUkTY4PTElS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVbm6cooh4OXAYuBY4A+wBloAWsD0zFyPiDuD6av/NmflIRFzRr7buk5AkDTZyRR8RLwA+C/xvNbQL2JGZG4EZYFtEXA1sAtYBNwJ3Dqqtd/qSpFHGuXTzCeBu4D+r1/PAwWp7P7AF2AAcyMylzHwKmIuISwbUSpImaOilm4i4CfifzLw/Im6rhmcyc6naPgVcDKwFjne99dx4v9qRWq3WeLMfQ6PRqO1Yy63VatFut6c9jaHsZ73sZ33s5WCjrtG/F1iKiC3A64A/BV7etX8NcAI4WW33ji/2GRup2WzW+0vbd6y+Yy2jZrM57SmMx37Wy37W5wLtZbvdHrpAHnrpJjPfnJmbMnMz8E3gN4D9EbG5KrkOWAAOAVsjYjYiLgNmM/Np4EifWknSBI11102PW4DdEbEKeBzYm5lnI2IBeJDOh8f2QbU1zFmS9CyMHfTVqv6cTX327wR29owd7VcrSZocH5iSpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFmxtVEBEXAbuBAJaADwA/BPZUr1vA9sxcjIg7gOuBM8DNmflIRFzRr7b+U5Ek9TPOiv4GgMx8E7AD+D1gF7AjMzcCM8C2iLga2ASsA24E7qzef15trWcgSRpqZNBn5l8D769evgo4AcwDB6ux/cAWYANwIDOXMvMpYC4iLhlQK0makJGXbgAy80xEfAF4B/CrwLWZuVTtPgVcDKwFjne97dz4TJ/aoVqt1nizH0Oj0ajtWMut1WrRbrenPY2h7Ge97Gd97OVgYwU9QGb+ZkR8BHgYeGHXrjV0Vvknq+3e8cU+Y0M1m816f2n7jtV3rGXUbDanPYXx2M962c/6XKC9bLfbQxfIIy/dRMSvR8Rt1csf0Anuf4iIzdXYdcACcAjYGhGzEXEZMJuZTwNH+tRKkiZknBX9XwGfj4i/B14A3Aw8DuyOiFXV9t7MPBsRC8CDdD5Atlfvv6W3tuZzkCQNMTLoM/P7wK/12bWpT+1OYGfP2NF+tZKkyfCBKUkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCzQ3bGREvAD4HvBpoAL8L/AuwB1gCWsD2zFyMiDuA64EzwM2Z+UhEXNGvdlnORJLU16gV/buB45m5EXgr8BlgF7CjGpsBtkXE1cAmYB1wI3Bn9f7zaus/BUnSMKOC/kvA7dX2DJ3V+jxwsBrbD2wBNgAHMnMpM58C5iLikgG1kqQJGnrpJjO/BxARa4C9wA7gE5m5VJWcAi4G1gLHu956bnymT+1IrVZr3PmP1Gg0ajvWcmu1WrTb7WlPYyj7WS/7WR97OdjQoAeIiFcC9wJ3ZeafR8Qfdu1eA5wATlbbveOLfcZGajab9f7S9h2r71jLqNlsTnsK47Gf9bKf9blAe9lut4cukIdeuomInwYOAB/JzM9Vw0ciYnO1fR2wABwCtkbEbERcBsxm5tMDaiVJEzRqRf9R4KXA7RFx7lr9B4FPR8Qq4HFgb2aejYgF4EE6Hx7bq9pbgN3dtXWfgCRpuFHX6D9IJ9h7bepTuxPY2TN2tF+tJGlyfGBKkgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFc6gl6TCGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVbm6coohYB/xBZm6OiCuAPcAS0AK2Z+ZiRNwBXA+cAW7OzEcG1dZ/GpKkQUau6CPiw8A9wOpqaBewIzM3AjPAtoi4GtgErANuBO4cVFvv9CVJo4xz6eYJ4J1dr+eBg9X2fmALsAE4kJlLmfkUMBcRlwyolSRN0MhLN5n55Yh4ddfQTGYuVdungIuBtcDxrppz4/1qR2q1WuOUjaXRaNR2rOXWarVot9vTnsZQ9rNe9rM+9nKwsa7R9+i+xr4GOAGcrLZ7x/vVjtRsNuv9pe07Vt+xllGz2Zz2FMZjP+tlP+tzgfay3W4PXSA/l7tujkTE5mr7OmABOARsjYjZiLgMmM3MpwfUSpIm6Lms6G8BdkfEKuBxYG9mno2IBeBBOh8e2wfV1jBnSdKzMFbQZ+a3gfXV9lE6d9j01uwEdvaM9a2VJE2OD0xJUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhTPoJalwBr0kFW5uuX9ARMwCdwFXAW3gfZl5bLl/riSpYxIr+rcDqzPzDcCtwCcn8DMlSZVlX9EDG4CvAGTmQxFxzZDaiwBOnz5d6wRef+laXrb6olqPWbdXvvTFtNvtaU9jLPazXvazPhdqL7sys+/JzywtLdX6A3tFxD3AlzNzf/X6KeDyzDzTW3v48OENwMKyTkiSyrVxfn7+gd7BSazoTwJrul7P9gv5yqPARuA7wNnlnpgkFeIi4FI6GXqeSQT9IeAG4C8jYj3w2KDC+fn5NnDep5EkaaQnBu2YRNDfC1wbEd8AZoD3TOBnSpIqy36NXpI0XT4wJUmFM+glqXAGvSQVzqB/DiLihRHRmPY8SmNP9XxSfX1LEfxj7Bgi4meB3we+C3wRuIfOff4fzMz7pjm3lSgibgA+A/wf8LHM/Itq/GuZ+YtTnZwuaBFxObALuAY4Q2cx/Bjwocw8Os25/TgmcXtlCe4GbgdeDewFrgR+COwHDPpn72PA6+j8I/pSRKzOzC/Quf1WmqZ7gNsy8+FzA9XzP58H3jS1Wf2YDPrxzGbmQeBgRLwlM/8bICIGPeGr4U5n5ncBImIb8LXqqzH87+VzEBFfB3ove80AS5n5xilMaSVb3R3y8KPv6JrWfGph0I8nq+/seX9m3gQQEbcC/zXVWa1c346IXcDtmXkqIt4J3A+8ZMrzWqluBXYD76BzuUHP3T9FxOfofBHjM3S+vuVtwD9PdVY/JoN+PL8F3JCZi11j/wF8ekrzWeneC7ybagWfmf8eEW8BbpvqrFaozHw4Iv4M+PnMvHfa81nhfpvOV6tvANbS+a6u++g84b9i+cdYSSpcMbcPSZL6M+glqXAGvSQVzqCXpMIZ9JJUuP8HPOtbzOT7w5oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_sm, y_sm = sm.fit_sample(X_sm, y_sm.ravel())\n",
    "pd.Series(y_sm).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(X, y, estimator, **kwargs):\n",
    "\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    model = Pipeline([\n",
    "         ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore')), \n",
    "         ('estimator', estimator)\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train, **kwargs)  \n",
    "    \n",
    "    expected  = y_test\n",
    "    predicted = model.predict(X_test)\n",
    "    \n",
    "    # Compute and return F1 (harmonic mean of precision and recall)\n",
    "    print(\"{}: {}\".format(estimator.__class__.__name__, f1_score(expected, predicted, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: 0.38736946792640475\n",
      "NuSVC: 0.3538040775733466\n",
      "LinearSVC: 0.3677274987568374\n",
      "SGDClassifier: 0.33590253605171555\n",
      "KNeighborsClassifier: 0.3299353555445052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisahuynh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.3722028841372451\n",
      "ExtraTreesClassifier: 0.38214818498259573\n",
      "RandomForestClassifier: 0.38264545002486333\n",
      "GradientBoostingClassifier: 0.36524117354549973\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    SVC(), NuSVC(), LinearSVC(), \n",
    "    SGDClassifier(), KNeighborsClassifier(), \n",
    "    LogisticRegression(), \n",
    "    #aggingClassifier(), \n",
    "    ExtraTreesClassifier(n_estimators=100), \n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    GradientBoostingClassifier(n_estimators=100,learning_rate=.3)\n",
    "    #learning_rate=.5,max_depth=4, min_samples_leaf=75\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    score_model(X_sm, y_sm, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSearch Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current parameters used\n",
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt', 'log2'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
      " 'random_state': [None, 1, 33, 42, 55]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "random_state = [None, 1,33,42,55]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "               'random_state': random_state}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best parameters from fitting the random search\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train, Y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(train_features, train_labels)\n",
    "grid_search.best_params_\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, test_features, test_labels)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the model on train set \n",
    "model = SVC() \n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.33      0.35      1003\n",
      "           1       0.28      0.24      0.26      1043\n",
      "           2       0.20      0.03      0.05       581\n",
      "           3       0.42      0.65      0.51      1395\n",
      "\n",
      "    accuracy                           0.38      4022\n",
      "   macro avg       0.32      0.31      0.29      4022\n",
      "weighted avg       0.34      0.38      0.34      4022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the model on train set \n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.32      0.35      1003\n",
      "           1       0.30      0.21      0.25      1043\n",
      "           2       0.12      0.00      0.01       581\n",
      "           3       0.42      0.74      0.53      1395\n",
      "\n",
      "    accuracy                           0.39      4022\n",
      "   macro avg       0.31      0.32      0.29      4022\n",
      "weighted avg       0.34      0.39      0.34      4022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the model on train set \n",
    "model = RandomForestClassifier(bootstrap=True, max_features='sqrt', \n",
    "                               criterion='entropy',n_estimators=500, \n",
    "                               random_state=42, min_samples_leaf=4, min_samples_split=5)\n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.31      0.35      1003\n",
      "           1       0.29      0.23      0.26      1043\n",
      "           2       0.14      0.00      0.01       581\n",
      "           3       0.41      0.71      0.52      1395\n",
      "\n",
      "    accuracy                           0.38      4022\n",
      "   macro avg       0.31      0.31      0.28      4022\n",
      "weighted avg       0.34      0.38      0.34      4022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the model on train set \n",
    "model = RandomForestClassifier(random_state = 1,\n",
    "                                  n_estimators = 750,\n",
    "                                  max_depth = 15, \n",
    "                                  min_samples_split = 5,  min_samples_leaf = 1)\n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the model on train set \n",
    "model = GradientBoostingClassifier() \n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the model on train set \n",
    "model = ExtraTreesClassifier() \n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
