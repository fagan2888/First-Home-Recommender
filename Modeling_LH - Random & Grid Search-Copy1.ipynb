{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "import matplotlib\n",
    "import warnings\n",
    "import yellowbrick as yb\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect( \n",
    "                        host = 'project.cgxhdwn5zb5t.us-east-1.rds.amazonaws.com',\n",
    "                        port = 5432, \n",
    "                        user = 'postgres',\n",
    "                        password = 'Admin123',\n",
    "                        database = 'postgres')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEC2FLOAT = psycopg2.extensions.new_type(\n",
    "    psycopg2.extensions.DECIMAL.values,\n",
    "    'DEC2FLOAT',\n",
    "    lambda value, curs: float(value) if value is not None else None)\n",
    "psycopg2.extensions.register_type(DEC2FLOAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('Select * from \"ahshouseholdclass2\"')\n",
    "rows = cursor.fetchall()\n",
    "col_names = []\n",
    "for elt in cursor.description:\n",
    "    col_names.append(elt[0])\n",
    "\n",
    "df = pd.DataFrame(data=rows, columns=col_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'CONTROL', 'YEAR', 'RATINGHS_BIN', 'BEDROOMS', 'STORIES',\n",
       "       'PERPOVLVL', 'HHADLTKIDS', 'HINCP', 'UNITSIZE', 'NUMVETS', 'LOTSIZE',\n",
       "       'UFINROOMS', 'HHAGE', 'PARTNER', 'OTHERAMT', 'KITCHENS', 'NUMSECFAM',\n",
       "       'OILAMT', 'DINING', 'FINCP', 'NUMELDERS', 'WATERAMT', 'GASAMT',\n",
       "       'TOTROOMS', 'HHYNGKIDS', 'NUMSUBFAM', 'BATHROOMS', 'NUMYNGKIDS',\n",
       "       'TRASHAMT', 'NUMOLDKIDS', 'NUMNONREL', 'NUMPEOPLE', 'HHMOVE', 'UTILAMT',\n",
       "       'ELECAMT', 'NUMADULTS', 'MULTIGEN', 'LAUNDY', 'HHOLDKIDS', 'FINROOMS',\n",
       "       'LN_HINCP', 'LN_FINCP', 'HINCP_BIN', 'FINCP_BIN', 'NUMCARE', 'NUMWALK',\n",
       "       'HHRACE', 'OMB13CBSA', 'HSHLDTYPE', 'MVG3COST', 'MVG2COST', 'MILHH',\n",
       "       'HHMAR', 'HHNATVTY', 'COOKFUEL', 'NUMMEMRY', 'NUMERRND', 'NUMSEE',\n",
       "       'BLD', 'NUMHEAR', 'MVG1COST', 'DIVISION', 'FIREPLACE', 'CONDO',\n",
       "       'OWNLOT', 'FRIDGE', 'FIRSTHOME', 'HHCARE', 'NOSTEP', 'WASHER', 'HHSEE',\n",
       "       'KITCHSINK', 'HHERRND', 'WINBARS', 'HHWALK', 'HHHEAR', 'HHSEX',\n",
       "       'HHMEMRY', 'GARAGE', 'DISHWASH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000.0, 50000.0]     2465\n",
       "(30000.0, 40000.0]     2409\n",
       "(20000.0, 30000.0]     2403\n",
       "(50000.0, 60000.0]     2220\n",
       "(60000.0, 70000.0]     2011\n",
       "(10000.0, 20000.0]     2003\n",
       "(70000.0, 80000.0]     1956\n",
       "(80000.0, 90000.0]     1737\n",
       "(90000.0, 100000.0]    1558\n",
       "(0.0, 10000.0]         1346\n",
       "Name: HINCP_BIN, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HINCP_BIN'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extremely satisfied    7021\n",
       "satisfied              5284\n",
       "not satisfied          4887\n",
       "very satisfied         2916\n",
       "Name: RATINGHS_BIN, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RATINGHS_BIN'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>CONTROL</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>RATINGHS_BIN</th>\n",
       "      <th>BEDROOMS</th>\n",
       "      <th>STORIES</th>\n",
       "      <th>PERPOVLVL</th>\n",
       "      <th>HHADLTKIDS</th>\n",
       "      <th>HINCP</th>\n",
       "      <th>UNITSIZE</th>\n",
       "      <th>...</th>\n",
       "      <th>HHSEE</th>\n",
       "      <th>KITCHSINK</th>\n",
       "      <th>HHERRND</th>\n",
       "      <th>WINBARS</th>\n",
       "      <th>HHWALK</th>\n",
       "      <th>HHHEAR</th>\n",
       "      <th>HHSEX</th>\n",
       "      <th>HHMEMRY</th>\n",
       "      <th>GARAGE</th>\n",
       "      <th>DISHWASH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11000006</td>\n",
       "      <td>2017</td>\n",
       "      <td>extremely satisfied</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11000023</td>\n",
       "      <td>2017</td>\n",
       "      <td>satisfied</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11000046</td>\n",
       "      <td>2017</td>\n",
       "      <td>extremely satisfied</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11000048</td>\n",
       "      <td>2017</td>\n",
       "      <td>very satisfied</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11000052</td>\n",
       "      <td>2017</td>\n",
       "      <td>not satisfied</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13200.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11000054</td>\n",
       "      <td>2017</td>\n",
       "      <td>satisfied</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71004.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>11000062</td>\n",
       "      <td>2017</td>\n",
       "      <td>not satisfied</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>11000066</td>\n",
       "      <td>2017</td>\n",
       "      <td>not satisfied</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>11000067</td>\n",
       "      <td>2017</td>\n",
       "      <td>satisfied</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>11000079</td>\n",
       "      <td>2017</td>\n",
       "      <td>satisfied</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   CONTROL  YEAR         RATINGHS_BIN  BEDROOMS  STORIES  PERPOVLVL  \\\n",
       "0      0  11000006  2017  extremely satisfied       3.0      1.0      361.0   \n",
       "1      1  11000023  2017            satisfied       3.0      3.0      501.0   \n",
       "2      2  11000046  2017  extremely satisfied       3.0      1.0       52.0   \n",
       "3      3  11000048  2017       very satisfied       4.0      3.0      406.0   \n",
       "4      4  11000052  2017        not satisfied       4.0      2.0      113.0   \n",
       "5      5  11000054  2017            satisfied       2.0      7.0      501.0   \n",
       "6      6  11000062  2017        not satisfied       2.0      1.0      104.0   \n",
       "7      7  11000066  2017        not satisfied       2.0      1.0      117.0   \n",
       "8      8  11000067  2017            satisfied       2.0      1.0      198.0   \n",
       "9      9  11000079  2017            satisfied       2.0      2.0      302.0   \n",
       "\n",
       "   HHADLTKIDS     HINCP  UNITSIZE  ...  HHSEE  KITCHSINK  HHERRND  WINBARS  \\\n",
       "0         0.0   58700.0       4.0  ...    2.0        1.0      2.0      2.0   \n",
       "1         0.0  100000.0       4.0  ...    2.0        1.0      2.0      2.0   \n",
       "2         0.0   15000.0       2.0  ...    2.0        1.0      2.0      2.0   \n",
       "3         0.0  100000.0       6.0  ...    2.0        1.0      2.0      2.0   \n",
       "4         0.0   13200.0       3.0  ...    2.0        1.0      2.0      2.0   \n",
       "5         0.0   71004.0       3.0  ...    2.0        1.0      2.0      2.0   \n",
       "6         0.0   30200.0       4.0  ...    2.0        1.0      2.0      2.0   \n",
       "7         1.0   29000.0       3.0  ...    2.0        1.0      2.0      2.0   \n",
       "8         0.0   25000.0       3.0  ...    2.0        1.0      1.0      2.0   \n",
       "9         0.0   59000.0       5.0  ...    2.0        1.0      2.0      2.0   \n",
       "\n",
       "   HHWALK  HHHEAR  HHSEX  HHMEMRY  GARAGE  DISHWASH  \n",
       "0     2.0     2.0    2.0      2.0     1.0       1.0  \n",
       "1     2.0     2.0    1.0      2.0     1.0       1.0  \n",
       "2     2.0     2.0    1.0      2.0     1.0       2.0  \n",
       "3     2.0     2.0    2.0      2.0     1.0       1.0  \n",
       "4     2.0     2.0    1.0      2.0     2.0       1.0  \n",
       "5     2.0     2.0    1.0      2.0     2.0       1.0  \n",
       "6     2.0     2.0    1.0      2.0     2.0       1.0  \n",
       "7     2.0     2.0    2.0      2.0     2.0       1.0  \n",
       "8     2.0     2.0    2.0      2.0     2.0       1.0  \n",
       "9     2.0     2.0    1.0      2.0     1.0       1.0  \n",
       "\n",
       "[10 rows x 81 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP = {\n",
    "\"(90000.0, 100000.0]\": 10,\n",
    "\"(80000.0, 90000.0]\": 9,\n",
    "\"(70000.0, 80000.0]\": 8,   \n",
    "\"(60000.0, 70000.0]\": 7,\n",
    "\"(50000.0, 60000.0]\": 6,\n",
    "\"(40000.0, 50000.0]\": 5,\n",
    "\"(30000.0, 40000.0]\": 4,\n",
    "\"(20000.0, 30000.0]\": 3,\n",
    "\"(10000.0, 20000.0]\": 2,\n",
    "\"(0.0, 10000.0]\": 1}\n",
    "\n",
    "# Convert categorical labels into incremental value\n",
    "df['HINCP_BIN'] = df['HINCP_BIN'].map(LABEL_MAP).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X = df[[\n",
    "    #'PERPOVLVL','NUMELDERS',  #'ELECAMT',#'UTILAMT', 'DIVISION',#'HHNATVTY', \n",
    "        #'BEDROOMS','OMB13CBSA','BATHROOMS', 'HHMOVE','UNITSIZE', 'HINCP_BIN',\n",
    "        #'HHWALK', 'HHHEAR', 'LAUNDY'\n",
    "        #'HHSEX','GARAGE', 'DISHWASH','DINING']]\n",
    "X = df[['HHAGE','HHMOVE','UTILAMT','PERPOVLVL','HINCP','LN_HINCP','FINCP','LN_FINCP','ELECAMT','WATERAMT','TRASHAMT', 'GASAMT' ]]\n",
    "y = df['RATINGHS_BIN']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm, y_sm = sm.fit_sample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x121252a58>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_sm, y_sm = sm.fit_sample(X_sm, y_sm.ravel())\n",
    "pd.Series(y_sm).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(X, y, estimator, **kwargs):\n",
    "\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    model = Pipeline([\n",
    "         ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore')), \n",
    "         ('estimator', estimator)\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train, **kwargs)  \n",
    "    \n",
    "    expected  = y_test\n",
    "    predicted = model.predict(X_test)\n",
    "    \n",
    "    # Compute and return F1 (harmonic mean of precision and recall)\n",
    "    print(\"{}: {}\".format(estimator.__class__.__name__, f1_score(expected, predicted, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: 0.3610144206862258\n",
      "NuSVC: 0.3314271506713078\n",
      "LinearSVC: 0.3167578319244157\n",
      "SGDClassifier: 0.3274490303331676\n",
      "KNeighborsClassifier: 0.299602187966186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisahuynh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.32148184982595723\n",
      "ExtraTreesClassifier: 0.3530581800099453\n",
      "RandomForestClassifier: 0.3453505718547986\n",
      "GradientBoostingClassifier: 0.33938339134758827\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    SVC(), NuSVC(), LinearSVC(), \n",
    "    SGDClassifier(), KNeighborsClassifier(), \n",
    "    LogisticRegression(), \n",
    "    #aggingClassifier(), \n",
    "    ExtraTreesClassifier(n_estimators=100), \n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    GradientBoostingClassifier(n_estimators=100,learning_rate=.3)\n",
    "    #learning_rate=.5,max_depth=4, min_samples_leaf=75\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    score_model(X_sm, y_sm, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: 0.38587767279960217\n",
      "NuSVC: 0.3508204873197414\n",
      "LinearSVC: 0.3814022874191944\n",
      "SGDClassifier: 0.34783689706613624\n",
      "KNeighborsClassifier: 0.3356539035305818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisahuynh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.3823968175037295\n",
      "ExtraTreesClassifier: 0.3538040775733466\n",
      "RandomForestClassifier: 0.3639980109398309\n",
      "GradientBoostingClassifier: 0.3712083540527101\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    SVC(), NuSVC(), LinearSVC(), \n",
    "    SGDClassifier(), KNeighborsClassifier(), \n",
    "    LogisticRegression(), \n",
    "    #aggingClassifier(), \n",
    "    ExtraTreesClassifier(n_estimators=100), \n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    GradientBoostingClassifier(n_estimators=100,learning_rate=.3)\n",
    "    #learning_rate=.5,max_depth=4, min_samples_leaf=75\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    score_model(X_train, y_train, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSearch Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current parameters used\n",
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifer()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best parameters from fitting the random search\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train, Y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': ['auto','sqrt', 'log2'],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.5min\n",
      "/Users/lisahuynh/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  7.3min\n",
      "/Users/lisahuynh/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/Users/lisahuynh/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/Users/lisahuynh/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 17.4min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2a2a91258c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    710\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    689\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 691\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6176a074e3ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the grid search to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m {'bootstrap': True,\n\u001b[1;32m      5\u001b[0m  \u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    710\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    689\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 691\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_\n",
    "\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, test_features, test_labels)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the model on train set \n",
    "model = SVC() \n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "extremely satisfied       0.42      0.72      0.53      1390\n",
      "      not satisfied       0.41      0.34      0.37      1010\n",
      "          satisfied       0.33      0.24      0.28      1062\n",
      "     very satisfied       0.20      0.01      0.01       560\n",
      "\n",
      "           accuracy                           0.40      4022\n",
      "          macro avg       0.34      0.33      0.30      4022\n",
      "       weighted avg       0.36      0.40      0.35      4022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random plug and chug parameters\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the model on train set \n",
    "model = RandomForestClassifier(bootstrap=True, max_features='sqrt', \n",
    "                               criterion='entropy',n_estimators=500, \n",
    "                               random_state=33, min_samples_leaf=4, min_samples_split=5)\n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "extremely satisfied       0.43      0.72      0.53      1390\n",
      "      not satisfied       0.41      0.33      0.37      1010\n",
      "          satisfied       0.33      0.26      0.29      1062\n",
      "     very satisfied       0.25      0.01      0.01       560\n",
      "\n",
      "           accuracy                           0.40      4022\n",
      "          macro avg       0.35      0.33      0.30      4022\n",
      "       weighted avg       0.37      0.40      0.36      4022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from gridsearch - best parameters\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the model on train set \n",
    "model = RandomForestClassifier(bootstrap=True, max_features='auto', \n",
    "                               criterion='gini',n_estimators=200, \n",
    "                               random_state=42, min_samples_leaf=4, warm_start=False)\n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "extremely satisfied       0.41      0.74      0.53      1410\n",
      "      not satisfied       0.37      0.31      0.34       987\n",
      "          satisfied       0.31      0.20      0.24      1021\n",
      "     very satisfied       0.00      0.00      0.00       604\n",
      "\n",
      "           accuracy                           0.39      4022\n",
      "          macro avg       0.27      0.31      0.28      4022\n",
      "       weighted avg       0.31      0.39      0.33      4022\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisahuynh/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lisahuynh/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lisahuynh/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#from random search - best parameters\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the model on train set \n",
    "model = RandomForestClassifier(bootstrap=True, max_features= 'sqrt', \n",
    "                               max_depth=10, n_estimators=200,\n",
    "                               min_samples_leaf=2,\n",
    "                               min_samples_split= 5)\n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "extremely satisfied       0.42      0.69      0.52      1410\n",
      "      not satisfied       0.39      0.33      0.35       987\n",
      "          satisfied       0.30      0.24      0.27      1021\n",
      "     very satisfied       0.25      0.01      0.02       604\n",
      "\n",
      "           accuracy                           0.39      4022\n",
      "          macro avg       0.34      0.32      0.29      4022\n",
      "       weighted avg       0.35      0.39      0.34      4022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the model on train set \n",
    "model = RandomForestClassifier(bootstrap=True, max_features= 'sqrt', \n",
    "                               max_depth=200, n_estimators=500,\n",
    "                               min_samples_leaf=2,\n",
    "                               min_samples_split= 10)\n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the model on train set \n",
    "model = GradientBoostingClassifier() \n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#train the model on train set \n",
    "model = ExtraTreesClassifier() \n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
